{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8866e334-e4b4-48ff-b9b4-498ba03ff964",
   "metadata": {},
   "source": [
    "# File Cleaner and Organizer\n",
    "This is the Notebook for the File Cleaner and Organizer App. The main app is on the .py file, but the notebook makes it easier to understand and try new changes! Feel free to download it and tweek the parameters and functions.\n",
    "The main objective is to clean folders, like my 'Downloads' Folder that was a mess. While making the app, it came to mind that clustering can be really helpful for this, as it can group similar files and make the organizing more effective. Let's see how it works in this implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890b6a2-4aef-40cf-aa51-82548aacf122",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "497ef58e-bdfb-486d-b3fa-be7e477bd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d83af-ef43-4e5e-9742-77807acbd70d",
   "metadata": {},
   "source": [
    "## Information extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "20e68a1b-b863-42e6-a07e-25bcfe3ad4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract info about the files\n",
    "def extract_file_info(folder_path): # returns for each file: [file_name, file_type, file_size, creation_date]\n",
    "    info_list = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            file_type = os.path.splitext(file_path)[1][1:]\n",
    "            file_size = os.path.getsize(file_path) / 1024\n",
    "            creation_time = os.path.getctime(file_path)\n",
    "            creation_date = datetime.fromtimestamp(creation_time).strftime('%Y-%m-%d')\n",
    "            info_list.append([file_name, file_type, file_size, creation_date])\n",
    "    #info_df = pd.DataFrame(info_list, columns=['File Name', 'File Type', 'File Size (KB)', 'Creation Date'])\n",
    "    return info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "96eecc0e-d842-48e7-ba19-250ecfa59551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['actor.csv', 'csv', 4.33203125, '2024-05-30'],\n",
       " ['film.csv', 'csv', 179.3955078125, '2024-05-30'],\n",
       " ['film_actor.csv', 'csv', 44.63671875, '2024-05-30'],\n",
       " ['test.ipynb', 'ipynb', 0.8046875, '2024-05-31'],\n",
       " ['test_spark_session.py', 'py', 0.248046875, '2024-05-31']]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masters_path = r'C:\\Users\\rodri\\OneDrive\\Documents\\Spark'\n",
    "extract_file_info(masters_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fa38f-b875-43bf-86a8-4952a56e4ee1",
   "metadata": {},
   "source": [
    "## File Organizer by Type (Straightforward way, no ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fe73ade-9aba-4523-a773-82c916271e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_files_by_type(folder_path, info_list):\n",
    "    for file_info in info_list:\n",
    "        file_name = file_info[0]\n",
    "        file_type = file_info[1]\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f\"Processing file: {file_path}\")  # Debug print\n",
    "        if os.path.isfile(file_path):\n",
    "            type_folder_path = os.path.join(folder_path, file_type)\n",
    "            target_path = os.path.join(type_folder_path, file_name)\n",
    "            if not os.path.exists(type_folder_path):\n",
    "                os.makedirs(type_folder_path)\n",
    "                print(f\"Created directory: {type_folder_path}\")  # Debug print\n",
    "            shutil.move(file_path, target_path)\n",
    "            print(f\"Moved {file_path} to {target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be4f4b01-e6d0-475f-afb2-baa307baaa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\scholaro-gpa UOL.pdf\n",
      "Moved C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\scholaro-gpa UOL.pdf to C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\pdf\\scholaro-gpa UOL.pdf\n",
      "Processing file: C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\Ugarte Sanguineti_certificate.pdf\n",
      "Moved C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\Ugarte Sanguineti_certificate.pdf to C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\pdf\\Ugarte Sanguineti_certificate.pdf\n",
      "Processing file: C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\UOL transcript.pdf\n",
      "Moved C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\UOL transcript.pdf to C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS\\pdf\\UOL transcript.pdf\n"
     ]
    }
   ],
   "source": [
    "masters_path = r'C:\\Users\\rodri\\OneDrive\\Documents\\MASTERS'\n",
    "masters_info = extract_file_info(masters_path)\n",
    "organize_files_by_type(masters_path, masters_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0837e1-5a00-4655-8255-f115cc1e61ba",
   "metadata": {},
   "source": [
    "## Clustering implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c372ca3c-6f2b-4b77-ae09-68daefff74cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['011cbd17-26c8-41bc-98d4-22aab6f0c8b4.pdf',\n",
       "  'pdf',\n",
       "  33.259765625,\n",
       "  '2024-03-01'],\n",
       " ['107065230_10222958673178213_1447619766009901457_n.jpg',\n",
       "  'jpg',\n",
       "  382.1611328125,\n",
       "  '2024-04-01'],\n",
       " ['292592821_5527017737320938_5845818422473006150_n.jpg',\n",
       "  'jpg',\n",
       "  48.2568359375,\n",
       "  '2024-05-27'],\n",
       " ['about.jpg', 'jpg', 53.3193359375, '2023-08-31'],\n",
       " ['Alejandra Siu 17.doc', 'doc', 776.5, '2023-08-22'],\n",
       " ['Anaconda3-2024.02-1-Windows-x86_64.exe',\n",
       "  'exe',\n",
       "  926074.5078125,\n",
       "  '2024-05-29'],\n",
       " ['Analista de Planeamiento Financiero y Control de Gestión_v3.docx',\n",
       "  'docx',\n",
       "  18.8115234375,\n",
       "  '2023-11-12'],\n",
       " ['Application_Form-2024_Call1.xlsx', 'xlsx', 279.1279296875, '2024-04-22'],\n",
       " ['Appointment Booked - ESHC My Student Health Record.pdf',\n",
       "  'pdf',\n",
       "  56.55859375,\n",
       "  '2024-04-16'],\n",
       " ['app_print.pdf', 'pdf', 52.642578125, '2024-04-14'],\n",
       " ['beers-tables.sql', 'sql', 2.806640625, '2024-02-14'],\n",
       " ['BFRO (1).zip', 'zip', 9173.5185546875, '2024-04-26'],\n",
       " ['BFRO.zip', 'zip', 9173.5185546875, '2024-04-25'],\n",
       " ['bibs.xml', 'xml', 0.6435546875, '2024-02-07'],\n",
       " ['CamScanner 11-11-2023 21.18.pdf', 'pdf', 239.3056640625, '2023-11-12'],\n",
       " ['carta-mayta-english.pdf', 'pdf', 663.072265625, '2024-02-14'],\n",
       " ['CartaOsaka_Pya_WEB__Lima_Castellano_COMIDA.pdf',\n",
       "  'pdf',\n",
       "  1774.556640625,\n",
       "  '2023-12-07'],\n",
       " ['CATALOGO PBA Regalos Navideños (1).pdf', 'pdf', 8719.09375, '2023-12-20'],\n",
       " ['CERTIFICADO_PYTHON FUNDAMENTALS FOR DATA SCIENCE_RODRIGO BENJAMIN UGARTE....pdf',\n",
       "  'pdf',\n",
       "  339.3115234375,\n",
       "  '2023-07-12'],\n",
       " ['CERTIFICADO_SQL Y MODELAMIENTO DE DATOS - SQL SERVER 2019_UGARTE SANGUINETI, RODRIGO BENJAMIN (1).pdf',\n",
       "  'pdf',\n",
       "  591.650390625,\n",
       "  '2023-07-07'],\n",
       " ['CIRCUITO TESOROS DE TURQUÍA Y GRECIA SALIDAS MAR-OCT 2024 - AGENCIA DINERS TRAVEL.pdf',\n",
       "  'pdf',\n",
       "  267.5341796875,\n",
       "  '2024-04-30'],\n",
       " ['Copia de Cuestionario SST_Vig_v3(1) (1).xlsx',\n",
       "  'xlsx',\n",
       "  753.0087890625,\n",
       "  '2024-03-19'],\n",
       " ['Copia de Cuestionario SST_Vig_v3(1).xlsx',\n",
       "  'xlsx',\n",
       "  753.0087890625,\n",
       "  '2024-03-19'],\n",
       " ['CV Rodrigo Ugarte (1).pdf', 'pdf', 189.3720703125, '2024-02-14'],\n",
       " ['CV_Flores_Carlos_english.pdf', 'pdf', 104.2529296875, '2024-02-26'],\n",
       " ['desktop.ini', 'ini', 0.275390625, '2021-12-22'],\n",
       " ['Docker Desktop Installer.exe', 'exe', 500307.1015625, '2024-04-08'],\n",
       " ['DSCI 551 Syllabus- Sp24.pdf', 'pdf', 311.2265625, '2024-01-10'],\n",
       " ['DSCI 551 Syllabus-Fa231.pdf', 'pdf', 314.0966796875, '2023-12-08'],\n",
       " ['DSCI-550_2.zip', 'zip', 59201.5302734375, '2024-03-06'],\n",
       " ['DSCI-551 Midterm2.pdf', 'pdf', 88.9375, '2024-03-27'],\n",
       " ['dsci-552-formulae.pdf', 'pdf', 1340.083984375, '2023-09-04'],\n",
       " ['dsci551-15906-default-rtdb-export.json',\n",
       "  'json',\n",
       "  0.0263671875,\n",
       "  '2024-01-17'],\n",
       " ['dsci551.pem', 'pem', 1.634765625, '2024-01-10'],\n",
       " ['e0e184a9-ccdc-422c-aafd-28ddd7ff0d3b.jpg', 'jpg', 47.953125, '2024-04-05'],\n",
       " ['file.enc', 'enc', 2.77734375, '2024-02-05'],\n",
       " ['GeneralWaiver (1) (1).pdf', 'pdf', 15.5732421875, '2024-02-11'],\n",
       " ['GeneralWaiver (1).pdf', 'pdf', 15.5732421875, '2024-02-11'],\n",
       " ['GeneralWaiver.pdf', 'pdf', 11.85546875, '2024-02-11'],\n",
       " ['Grecia-20240529T132338Z-001.zip', 'zip', 1405231.259765625, '2024-05-29'],\n",
       " ['helper.py', 'py', 0.328125, '2024-02-07'],\n",
       " ['hw3-551-sp24_rubrics.docx', 'docx', 127.560546875, '2024-03-24'],\n",
       " ['hw4-551-sp24.pdf', 'pdf', 52.8837890625, '2024-03-20'],\n",
       " ['ImageCatIndex.tar.gz', 'gz', 1696.578125, '2024-04-26'],\n",
       " ['INFORME DIAGNOSTICAR AYK672.pdf', 'pdf', 1774.345703125, '2024-03-31'],\n",
       " ['Lab 3 (1).txt', 'txt', 3.37109375, '2024-03-20'],\n",
       " ['Lab 3.txt', 'txt', 3.37109375, '2024-03-20'],\n",
       " ['Lab4.pdf', 'pdf', 52.619140625, '2024-04-06'],\n",
       " ['midterm-2 2023.pdf', 'pdf', 7703.9443359375, '2024-03-27'],\n",
       " ['mysql-workbench-community-8.0.36-winx64.msi', 'msi', 43000.0, '2024-03-01'],\n",
       " ['Nakamura-Abasov.pgn', 'pgn', 1.5908203125, '2024-04-15'],\n",
       " ['node-v20.12.1-x64.msi', 'msi', 25936.0, '2024-04-09'],\n",
       " ['NOSOTROS SOBREVIVIENDO EN UNA ISLA+ BONUS.pptx',\n",
       "  'pptx',\n",
       "  5735.6376953125,\n",
       "  '2023-07-31'],\n",
       " ['Oferta Compensatoria - Analista de Planeamiento Financiero y Control de Gestión.docx',\n",
       "  'docx',\n",
       "  15.2802734375,\n",
       "  '2023-11-12'],\n",
       " ['onepiece_1106_side_011.png', 'png', 2786.95703125, '2024-02-01'],\n",
       " ['Praggnanandhaa R_vs_Nakamura, Hikaru.pgn',\n",
       "  'pgn',\n",
       "  2.5419921875,\n",
       "  '2024-04-17'],\n",
       " ['Presentación_SGMOD_2023.pptx', 'pptx', 1730.41796875, '2023-05-12'],\n",
       " ['putty-64bit-0.80-installer.msi', 'msi', 3622.5, '2024-02-12'],\n",
       " ['PXL_20230801_145906110.jpg', 'jpg', 2131.37890625, '2023-12-22'],\n",
       " ['PXL_20230813_175740490.jpg', 'jpg', 3360.828125, '2023-09-17'],\n",
       " ['PXL_20230813_193334835.jpg', 'jpg', 2520.642578125, '2023-09-17'],\n",
       " ['python-3.11.9-amd64.exe', 'exe', 25602.3828125, '2024-05-29'],\n",
       " ['Python-and-Spark-for-Big-Data-master.zip',\n",
       "  'zip',\n",
       "  1706.7392578125,\n",
       "  '2024-05-31'],\n",
       " ['query-execution.pdf', 'pdf', 812.765625, '2024-04-24'],\n",
       " ['query-execution.ppt', 'ppt', 1348.5, '2024-04-24'],\n",
       " ['Rafaella Treno  - Hoja 1.pdf', 'pdf', 32.658203125, '2023-11-21'],\n",
       " ['reports.csv', 'csv', 16308.3544921875, '2024-02-27'],\n",
       " ['ResponseSummary.pdf', 'pdf', 32.5234375, '2023-12-22'],\n",
       " ['Resume Rodrigo Ugarte.docx', 'docx', 3795.1455078125, '2024-05-23'],\n",
       " ['Resume Rodrigo Ugarte.docx.pdf', 'pdf', 59.0966796875, '2024-05-23'],\n",
       " ['Resume Rodrigo Ugarte.pdf', 'pdf', 179.267578125, '2024-05-27'],\n",
       " ['SBR - Volumen 04 (El destino de Gyro Zeppeli).pdf',\n",
       "  'pdf',\n",
       "  100065.548828125,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 05 (La conspiración del presidente).pdf',\n",
       "  'pdf',\n",
       "  111336.2880859375,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 06 (Scary Monsters).pdf',\n",
       "  'pdf',\n",
       "  90604.55078125,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 07 (La pequeña tumba en la gran, gran pradera).pdf',\n",
       "  'pdf',\n",
       "  101939.0615234375,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 08 (Al Mundo de los Hombres).pdf',\n",
       "  'pdf',\n",
       "  100887.7412109375,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 09 (Una noche de tormenta se acerca).pdf',\n",
       "  'pdf',\n",
       "  107141.5234375,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 10 (Illinois Skyline - Michigan Lakeline).pdf',\n",
       "  'pdf',\n",
       "  86834.11328125,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 11 (¡Construye el rectángulo áureo!).pdf',\n",
       "  'pdf',\n",
       "  99921.494140625,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 12 (Las condiciones para el cuerpo, las condiciones para la amistad).pdf',\n",
       "  'pdf',\n",
       "  89983.181640625,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 13 (La bola de acero se rompe).pdf',\n",
       "  'pdf',\n",
       "  90518.5947265625,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 14 (Las cualificaciones del vencedor).pdf',\n",
       "  'pdf',\n",
       "  96712.453125,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 15 (El sueño de Gettysburg).pdf',\n",
       "  'pdf',\n",
       "  100853.3486328125,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 16 (Actos Sucios A Bajo Costo).pdf',\n",
       "  'pdf',\n",
       "  82956.794921875,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 17 (D4C).pdf', 'pdf', 98852.1865234375, '2024-06-05'],\n",
       " ['SBR - Volumen 18 (Ticket to Ride - Boleto de lágrimas).pdf',\n",
       "  'pdf',\n",
       "  84137.65625,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 19 (No puedes volverte rico).pdf',\n",
       "  'pdf',\n",
       "  91537.697265625,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 20 (Love Train - El mundo es uno).pdf',\n",
       "  'pdf',\n",
       "  88802.1640625,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 21 (Ball Breaker).pdf',\n",
       "  'pdf',\n",
       "  89300.6689453125,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 22 (Break My Heart, Break Your Heart).pdf',\n",
       "  'pdf',\n",
       "  84476.375,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 23 (High Voltage).pdf',\n",
       "  'pdf',\n",
       "  111880.7548828125,\n",
       "  '2024-06-05'],\n",
       " ['SBR - Volumen 24 (Mundo de barras y estrellas para siempre).pdf',\n",
       "  'pdf',\n",
       "  118327.611328125,\n",
       "  '2024-06-05'],\n",
       " ['Screenshot 2023-09-11 173531.png', 'png', 297.8916015625, '2023-09-11'],\n",
       " ['Screenshot 2023-11-13 214403.png', 'png', 324.0458984375, '2023-11-14'],\n",
       " ['Screenshot 2024-03-24 152316.png', 'png', 116.673828125, '2024-03-24'],\n",
       " ['Screenshot 2024-03-28 154123.png', 'png', 110.33984375, '2024-03-29'],\n",
       " ['Screenshot 2024-05-03 224124.jpg', 'jpg', 68.9921875, '2024-05-03'],\n",
       " ['setup-x86_64.exe', 'exe', 1361.5185546875, '2024-01-10'],\n",
       " ['setup.py', 'py', 1.7119140625, '2024-03-31'],\n",
       " ['Signed_GeneralWaiver (1).pdf', 'pdf', 372.642578125, '2024-02-11'],\n",
       " ['Signed_GeneralWaiver.pdf', 'pdf', 372.642578125, '2024-02-11'],\n",
       " ['SQL2MR.java', 'java', 3.525390625, '2024-04-15'],\n",
       " ['SU24 GRD addendum FIN.pdf', 'pdf', 1205.96484375, '2024-02-27'],\n",
       " ['TEAM_06_DSCI550_HW_EXTRACT.tsv', 'tsv', 21037.9833984375, '2024-04-29'],\n",
       " ['Turquia-20240529T132341Z-001.zip', 'zip', 1204705.513671875, '2024-05-29'],\n",
       " ['Ubuntu software installation.docx', 'docx', 459.708984375, '2024-01-19'],\n",
       " ['USC_OASIS_Enrollment history.pdf', 'pdf', 115.2255859375, '2024-02-16'],\n",
       " ['VirtualBox-7.0.18-162988-Win.exe', 'exe', 107129.046875, '2024-05-28'],\n",
       " ['WhatsApp Image 2024-02-05 at 10.33.27 PM.jpeg',\n",
       "  'jpeg',\n",
       "  320.4365234375,\n",
       "  '2024-02-06'],\n",
       " ['WhatsApp Image 2024-06-04 at 4.17.42 PM.jpeg',\n",
       "  'jpeg',\n",
       "  196.0244140625,\n",
       "  '2024-06-04'],\n",
       " ['WinSCP-6.1.2-Setup.exe', 'exe', 10871.53125, '2024-02-12'],\n",
       " ['without_text (1).zip', 'zip', 26299.2001953125, '2024-03-07'],\n",
       " ['~$ GRE1806C460.docx', 'docx', 0.158203125, '2022-08-23'],\n",
       " ['~WRL0763.tmp', 'tmp', 47.5, '2022-09-05'],\n",
       " ['~WRL1515.tmp', 'tmp', 33.3466796875, '2022-08-10'],\n",
       " ['~WRL1547.tmp', 'tmp', 33.7822265625, '2022-08-22']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masters_path = r'C:\\Users\\rodri\\Downloads'\n",
    "file_info = extract_file_info(masters_path)\n",
    "file_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09869afd-3180-460b-95fa-c28b8e02826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(file_info):\n",
    "    df = pd.DataFrame(file_info, columns=['file name', 'file type', 'file size (KB)', 'creation date'])\n",
    "    # featurize the file names\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    name_features = vectorizer.fit_transform(df['file name'])\n",
    "    # one hot encode file types\n",
    "    type_features = pd.get_dummies(df['file type'])\n",
    "    # scale features\n",
    "    scaler = StandardScaler()\n",
    "    size_features = scaler.fit_transform(df[['file size (KB)']])\n",
    "    date_features = scaler.fit_transform(pd.to_datetime(df['creation date']).values.reshape(-1, 1))\n",
    "\n",
    "    # create new df with all the features\n",
    "    combined_features = pd.concat([\n",
    "        pd.DataFrame(name_features.toarray()),\n",
    "        type_features.reset_index(drop=True),\n",
    "        pd.DataFrame(size_features, columns=['file size']),\n",
    "        pd.DataFrame(date_features, columns=['creation date'])], axis=1)\n",
    "    combined_features.columns = combined_features.columns.astype(str)\n",
    "    \n",
    "    return combined_features, df['file name'], vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "222252be-e2f9-4d09-8156-d294087bc7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>py</th>\n",
       "      <th>sql</th>\n",
       "      <th>tmp</th>\n",
       "      <th>tsv</th>\n",
       "      <th>txt</th>\n",
       "      <th>xlsx</th>\n",
       "      <th>xml</th>\n",
       "      <th>zip</th>\n",
       "      <th>file size</th>\n",
       "      <th>creation date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.287094</td>\n",
       "      <td>0.133246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.285301</td>\n",
       "      <td>0.336535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.287017</td>\n",
       "      <td>0.703766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.286991</td>\n",
       "      <td>-1.066814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.283273</td>\n",
       "      <td>-1.125834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1    2    3    4    5    6    7    8    9  ...     py    sql  \\\n",
       "0  0.0  0.44184  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  False  False   \n",
       "1  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  False  False   \n",
       "2  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  False  False   \n",
       "3  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  False  False   \n",
       "4  0.0  0.00000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  False  False   \n",
       "\n",
       "     tmp    tsv    txt   xlsx    xml    zip  file size  creation date  \n",
       "0  False  False  False  False  False  False  -0.287094       0.133246  \n",
       "1  False  False  False  False  False  False  -0.285301       0.336535  \n",
       "2  False  False  False  False  False  False  -0.287017       0.703766  \n",
       "3  False  False  False  False  False  False  -0.286991      -1.066814  \n",
       "4  False  False  False  False  False  False  -0.283273      -1.125834  \n",
       "\n",
       "[5 rows x 341 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features, file_names, vectorizer = prepare_features(file_info)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "99233467-ec12-4ef3-a1e6-66e4496d2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_clustering(features):\n",
    "    num_files = features.shape[0]\n",
    "    k_values = range(5, (num_files//4)+1)\n",
    "    best_score = -1\n",
    "    best_k = -1\n",
    "    rand = np.random.randint(100)\n",
    "    \n",
    "    for k in k_values:\n",
    "        cluster = KMeans(n_clusters=k, random_state=rand)\n",
    "        cluster_labels = cluster.fit_predict(features)\n",
    "        score = silhouette_score(features, cluster_labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    print(f'The best k is {best_k} with a silhouette score of {best_score}')\n",
    "\n",
    "    cluster = KMeans(n_clusters=best_k, random_state=rand)\n",
    "    cluster_labels = cluster.fit_predict(features)\n",
    "    \n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0291fce5-b58a-4051-b7ad-747201d4b52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k is 18 with a silhouette score of 0.20325982000798307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9,  0,  0,  0,  8,  4, 15, 10,  9,  9, 16,  2,  2, 16,  5,  9,  5,\n",
       "        5,  5,  5,  9, 10, 10,  9,  9,  3, 13,  9,  5,  2,  9,  5,  7,  7,\n",
       "        0, 16,  9,  9,  9,  4, 12, 15,  9, 16,  9, 11, 11,  9,  9, 14, 17,\n",
       "       14,  8, 15,  6, 17,  8, 14,  0,  0,  0,  7,  2,  9, 16,  5, 16,  5,\n",
       "       15,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  0,  7, 12,  9,  9, 17,\n",
       "        9, 16,  4, 15,  9,  7, 16, 16,  7,  2,  3,  3,  3,  3])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = KMeans_clustering(features)\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048890b8-62d9-42e0-bbad-d4b5f7f52906",
   "metadata": {},
   "source": [
    "This is the most important function, extract the name of the organized folder based on the names of the folders within, honestly i was not expecting them to make sense, but with this example they turned out better than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bf3a5878-5316-4978-84ad-159735ab7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folder_names(file_names, labels, vectorizer, n_words):\n",
    "    folder_names = {}\n",
    "    for label in set(labels):\n",
    "        label_indices = np.where(labels == label)[0]\n",
    "        label_file_names = [file_names[i] for i in label_indices]\n",
    "        \n",
    "        # combine all the numbers in a single string for analysis\n",
    "        combined_names = \" \".join(label_file_names)\n",
    "        \n",
    "        # TF-IDF vectorizer to extract the most important terms\n",
    "        vectorized = vectorizer.transform([combined_names])\n",
    "        feature_array = np.array(vectorizer.get_feature_names_out())\n",
    "        tfidf_sorting = np.argsort(vectorized.toarray()).flatten()[::-1]\n",
    "        top_terms = feature_array[tfidf_sorting][:n_words] # this could need some work as i generally play with the number to make the most sense out of it\n",
    "        folder_name = \" \".join(top_terms)\n",
    "        folder_names[label] = folder_name\n",
    "    return folder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bf8fd8fa-59f5-4ea0-b05e-fa64b8714d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'jpg aafd',\n",
       " 1: 'volumen sbr',\n",
       " 2: 'zip bfro',\n",
       " 3: 'tmp gre1806c460',\n",
       " 4: '001 zip',\n",
       " 5: 'pdf benjamin',\n",
       " 6: 'png screenshot',\n",
       " 7: 'exe dsci551',\n",
       " 8: 'pptx doc',\n",
       " 9: 'pdf generalwaiver',\n",
       " 10: 'xlsx cuestionario',\n",
       " 11: 'lab txt',\n",
       " 12: 'py helper',\n",
       " 13: 'docker desktop',\n",
       " 14: 'msi 36',\n",
       " 15: 'docx de',\n",
       " 16: 'at jpeg',\n",
       " 17: 'pgn java'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_names = generate_folder_names(file_names, labels, vectorizer, 2) # 2 resulted to be concise and pretty useful for my case\n",
    "folder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a78b4647-ce47-4afc-aa01-ff8703301c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_files_clustering(base_path, file_names, labels, folder_names):\n",
    "    for folder_name in set(folder_names.values()):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "    \n",
    "    for file_name, label in zip(file_names, labels):\n",
    "        folder_name = folder_names[label]\n",
    "        source_path = os.path.join(base_path, file_name)\n",
    "        destination_path = os.path.join(base_path, folder_name, file_name)\n",
    "        shutil.move(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d65715d6-981c-4692-a73c-7fe968327d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_files_clustering(masters_path, file_names, labels, folder_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84da502-632d-40a5-9341-6bb523cfdc6e",
   "metadata": {},
   "source": [
    "For testing purposes, this is a function to revert the organization into files. So we can test other parameters and see how that affects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9576f38b-dd67-4ef0-a489-73c47d7d265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_organization(base_path):\n",
    "    for folder_name in os.listdir(base_path):\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                source_path = os.path.join(folder_path, file_name)\n",
    "                destination_path = os.path.join(base_path, file_name)\n",
    "                shutil.move(source_path, destination_path)\n",
    "            os.rmdir(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
